{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZ6UVblUt55HJRNvMJN6JP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 0. 코랩 이용 준비\n","---"],"metadata":{"id":"x-wBZGfYHWmZ"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYCPTHvpGveY","executionInfo":{"status":"ok","timestamp":1673528011303,"user_tz":-540,"elapsed":18580,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"19089691-52af-4bbe-86ce-4a8b6f086f92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["!ls /content/gdrive/MyDrive/Deep_Learning/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-aHRIFbHDRo","executionInfo":{"status":"ok","timestamp":1673528011762,"user_tz":-540,"elapsed":463,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"89260297-4a76-4803-9088-13548a4d09a2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["'cbow 실험.ipynb'\t\t\t\t Transfer_Learning\n"," colab_사용법.ipynb\t\t\t\t Untitled12.ipynb\n"," dataset\t\t\t\t\t'word2vec 오류난 부분.ipynb'\n","'모델을 구글 드라이브에 저장하기 실험실.ipynb'\t word2vec_수정.ipynb\n"," Learned_Parameters\t\t\t\t word2vec.ipynb\n"]}]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/Deep_Learning/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FkgaxFhHKI5","executionInfo":{"status":"ok","timestamp":1673528011763,"user_tz":-540,"elapsed":8,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"a4937179-0b47-4c18-84ca-87ca39030557"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Deep_Learning\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aelo0VfJHIFv","executionInfo":{"status":"ok","timestamp":1673528011763,"user_tz":-540,"elapsed":5,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"8e710074-ce27-4d4c-924a-b2e7ac91a480"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Deep_Learning\n"]}]},{"cell_type":"markdown","source":["# 1. 라이브러리 호출\n","---"],"metadata":{"id":"rgjnYEkPHSJu"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import collections # collections 모듈에는 데이터 처리를 위한 유용한 객체가 많이 있다. https://wikidocs.net/84392\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import time\n","\n","from dataset import ptb"],"metadata":{"id":"s7p9qAnuHQzt","executionInfo":{"status":"ok","timestamp":1673528015159,"user_tz":-540,"elapsed":3398,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# 2. 사용할 함수 추가\n","---"],"metadata":{"id":"Ow1yr-9_HeME"}},{"cell_type":"code","source":["def create_contexts_target(corpus, window_size=1):\n","    '''맥락과 타깃 생성\n","\n","    :param corpus: 말뭉치(단어 ID 목록)\n","    :param window_size: 윈도우 크기(윈도우 크기가 1이면 타깃 단어 좌우 한 단어씩이 맥락에 포함)\n","    :return:\n","    '''\n","    target = corpus[window_size:-window_size]\n","    contexts = []\n","\n","    for idx in range(window_size, len(corpus)-window_size):\n","        cs = []\n","        for t in range(-window_size, window_size + 1):\n","            if t == 0:\n","                continue\n","            cs.append(corpus[idx + t])\n","        contexts.append(cs)\n","\n","    return np.array(contexts), np.array(target)"],"metadata":{"id":"8Y9tNPSxHJaS","executionInfo":{"status":"ok","timestamp":1673528015159,"user_tz":-540,"elapsed":7,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# 3. device 설정\n","---"],"metadata":{"id":"fNrZLvWWHsij"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #  torch.cuda.is_available() GPU를 사용가능하면 True, 아니라면 False를 리턴\n","\n","print(\"지금 사용하는 device :\",device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fsXnQtFHucn","executionInfo":{"status":"ok","timestamp":1673528015159,"user_tz":-540,"elapsed":6,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"81a1a082-4299-4861-81bd-af988679e936"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["지금 사용하는 device : cuda:0\n"]}]},{"cell_type":"code","source":["print(torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSWI-CgjVHm9","executionInfo":{"status":"ok","timestamp":1673528015160,"user_tz":-540,"elapsed":7,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"6db49235-0299-4743-8357-926a121f0cb1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"markdown","source":["# 4. 데이터셋 준비\n","---"],"metadata":{"id":"KBQmyuOyHzVZ"}},{"cell_type":"code","source":["corpus, word_to_id, id_to_word = ptb.load_data('train')"],"metadata":{"id":"GRwJjMETH0ej","executionInfo":{"status":"ok","timestamp":1673528016422,"user_tz":-540,"elapsed":1267,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["contexts, target = create_contexts_target(corpus, 1)"],"metadata":{"id":"MY4V2_aKV7Ru","executionInfo":{"status":"ok","timestamp":1673528018723,"user_tz":-540,"elapsed":1595,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["임베딩에 들어가야 할 것은 long나 int인데\n","\n","파이토치로 역전파 계산하려면 float와 requires_grad=True가 필요한데 이 부분은 다음 참고\n","\n","https://hongl.tistory.com/244"],"metadata":{"id":"UChIfH7yIKV6"}},{"cell_type":"code","source":["class Corpus_Dataset(Dataset):\n","    def __init__(self, corpus, window_size = 1):\n","        contexts, target = create_contexts_target(corpus, window_size)\n","        self.contexts = contexts\n","        self.target = target\n","\n","    def __len__(self):\n","        return len(self.contexts)\n","\n","    def __getitem__(self, idx):\n","        contexts = torch.tensor(self.contexts[idx], dtype = torch.long)\n","        target = torch.tensor(self.target[idx], dtype = torch.long)\n","        return contexts, target"],"metadata":{"id":"zhuz19pTIJZw","executionInfo":{"status":"ok","timestamp":1673528018724,"user_tz":-540,"elapsed":5,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["데이터셋 준비 완료"],"metadata":{"id":"JzJ7wJfpXuLj"}},{"cell_type":"code","source":["dataset = Corpus_Dataset(corpus, window_size = 2)\n","dataloader = DataLoader(dataset, batch_size = 100)"],"metadata":{"id":"juXESfQdXiE9","executionInfo":{"status":"ok","timestamp":1673528023106,"user_tz":-540,"elapsed":4387,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# 5. 신경망 생성\n","---"],"metadata":{"id":"pzjvl1WtXy4f"}},{"cell_type":"markdown","source":["### 5.1 다음은 오류가 난 모델의 일부분이다. "],"metadata":{"id":"UddLdxK1Qfo8"}},{"cell_type":"code","source":["class pre_h(nn.Module):\n","    def __init__(self, vocab_size, hidden_size, window_size):\n","        super().__init__()\n","        self.window_size = window_size\n","        self.in_layer = nn.Embedding(vocab_size, hidden_size)\n","        self.weight_list = []\n","\n","    def forward(self, contexts):\n","        for i in range(2 * self.window_size):\n","            weight = self.in_layer(contexts[:,i])\n","            self.weight_list.append(weight)\n","\n","        h = sum(self.weight_list)\n","        h = h / len(self.weight_list)\n","\n","        return h\n"],"metadata":{"id":"ri9Shr16PPPk","executionInfo":{"status":"ok","timestamp":1673528023106,"user_tz":-540,"elapsed":8,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### 5.2 다음은 오류를 수정한 모델의 일부분이다."],"metadata":{"id":"nr4BAN4kQnTq"}},{"cell_type":"code","source":["class pre_h(nn.Module):\n","    def __init__(self, vocab_size, hidden_size, window_size):\n","        super().__init__()\n","        self.window_size = window_size\n","        self.in_layer = nn.Embedding(vocab_size, hidden_size)\n","        # self.weight_list = []\n","\n","    def forward(self, contexts):\n","        # 우민혁: h의 결과들을 리스트에 저장해서 sum하는 부분에서 에러가 발생한듯\n","        # 구체적인 이유는 모르겠음.\n","        # 따라서 에러를 방지하기 위해 반복문에 돌 때마다 바로 h = h + weight을 함\n","        h = 0\n","        for i in range(2 * self.window_size):\n","            weight = self.in_layer(contexts[:,i])\n","            # self.weight_list.append(weight)\n","            h = h + weight\n","        h = h / int(2 * self.window_size)\n","        # h = sum(self.weight_list)\n","        # h = h / len(self.weight_list)\n","\n","        return h\n"],"metadata":{"id":"3uLehVuRQudv","executionInfo":{"status":"ok","timestamp":1673528023106,"user_tz":-540,"elapsed":8,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["왜 오류가 난건지 정확히는 불명.\n","\n","그 이유도 구글링해봐도 나와있진 않는다. \n","\n","그저 겉면은 파이썬이나 속은 C++로 돌아가는 파이토치의 특성상 파이썬 기본 라이브러리가 잘 먹히지 않는듯...?\n"],"metadata":{"id":"2xtOTqXnQwCM"}},{"cell_type":"code","source":["vocab_size = len(id_to_word)\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r3NQMGNZUcjW","executionInfo":{"status":"ok","timestamp":1673528023106,"user_tz":-540,"elapsed":8,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"9558fdfa-c3e2-49c8-b9e2-d08ee676889a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n"]}]},{"cell_type":"code","source":["class UnigramSampler:\n","    '''\n","    말뭉치의 통계 데이터를 기초로 샘플링 하는 클래스\n","    말뭉치에서 각 단어의 출현 횟수를 구해 '확률분포'로 나타낸 다음 확률 분포대로 단어를 샘플링함\n","    '''\n","    def __init__(self, corpus, power, sample_size, device):\n","        super().__init__()\n","        self.sample_size = sample_size # 샘플링할 갯수\n","        self.vocab_size = None\n","        self.word_p = None\n","        self.device = device\n","\n","        counts = collections.Counter()\n","\n","        for word_id in corpus: # 말뭉치에서 단어를 꺼낸다 (이때 말뭉치는 단어 id로 이루어진 행렬이다.)\n","            counts[word_id] += 1 # 특정 단어가 몇번 나왔는지 숫자를 센다.\n","\n","        vocab_size = len(counts) # 총 단어의 갯수 이는 Counter의 특징을 알아야 한다.\n","        self.vocab_size = vocab_size\n","\n","        self.word_p = np.zeros(vocab_size) # 단어의 갯수 만큼 행렬 생성\n","\n","        for i in range(vocab_size):\n","            self.word_p[i] = counts[i] # 각 단어가 몇번 나왔었는지 텐서에 저장\n","\n","        self.word_p = np.power(self.word_p, power)\n","        self.word_p /= np.sum(self.word_p) # 기본 확률 분포에 0.75 제곱\n","\n","    def get_negative_sample(self, target): # 네거티브 샘플링\n","        batch_size = target.shape[0]\n","\n","        negative_sample = np.random.choice(self.vocab_size, size=(batch_size, self.sample_size), replace=True, p=self.word_p)\n","        negative_sample = torch.tensor(negative_sample).to(self.device) # 여기에 to(device)를 안하면 비교 대상이 GPU에 안올라가서 오류남\n","\n","        return negative_sample\n"],"metadata":{"id":"SNkwHXYEcEbC","executionInfo":{"status":"ok","timestamp":1673528039948,"user_tz":-540,"elapsed":2,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class NegativeSampling(nn.Module):\n","    def __init__(self, vocab_size, hidden_size, corpus, device, power = 0.75, sample_size = 5):\n","        super().__init__()\n","        self.sample_size = sample_size # 네거티브 샘플링 할 횟수\n","        self.sampler = UnigramSampler(corpus, power, sample_size, device) # 확률 분포에 따라서 샘플링 지정\n","\n","        self.embedding = nn.Embedding(vocab_size, hidden_size) # (hidden_size, vocab_size)\n","        self.sigmoid = nn.Sigmoid()\n","        self.loss_layer = nn.CrossEntropyLoss()\n","\n","        self.hidden_size = hidden_size\n","\n","    def forward(self, h, target):\n","        loss_data = 0\n","\n","        target = target.detach()\n","\n","        # 긍정적 예 샘플링\n","        w = self.embedding(target)\n","        w = torch.squeeze(w).reshape(self.hidden_size, -1)\n","        loss = h @ w\n","        loss = self.sigmoid(loss)\n","        correct_label = torch.ones_like(loss)\n","        loss = self.loss_layer(loss, correct_label)\n","        loss_data += loss\n","\n","        # 부정적 예로 타겟 변경\n","        negative_target = self.sampler.get_negative_sample(target)\n","\n","        # 부정적 예 샘플링\n","\n","        for i in range(self.sample_size):\n","            w = self.embedding(negative_target[:,i])\n","            w = torch.squeeze(w).reshape(self.hidden_size, -1)\n","            loss = h @ w\n","            loss = self.sigmoid(loss)\n","\n","            negative_label = torch.zeros_like(loss)\n","            loss = self.loss_layer(loss, negative_label)\n","\n","            loss_data += loss\n","\n","        return loss_data"],"metadata":{"id":"4G8yoqgEeQVg","executionInfo":{"status":"ok","timestamp":1673528071709,"user_tz":-540,"elapsed":1,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class sample_cbow(nn.Module): # 그저 단순히 두 부품을 합쳐봄\n","    def __init__(self, vocab_size, hidden_size, corpus, window_size, power = 0.75, sample_size = 5):\n","        super().__init__()\n","\n","        self.model_1 = pre_h(vocab_size, hidden_size, window_size)\n","        self.model_2 = NegativeSampling(vocab_size, hidden_size, corpus, power, sample_size)\n","\n","    def forward(self, contexts, target):\n","        out = self.model_1(contexts)\n","        out = self.model_2(out, target)\n","\n","        return out\n","\n"],"metadata":{"id":"MAoepjshuZwg","executionInfo":{"status":"ok","timestamp":1673524923719,"user_tz":-540,"elapsed":2,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["vocab_size = len(id_to_word)\n","model = sample_cbow(vocab_size, 100, corpus, 1)\n","\n","learning_rate = 0.001\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # 아담으로 옵티마이저 설정\n","\n","i = 1\n","\n","\n","for contexts, target in dataloader:\n","    print('===================================')\n","    print(i,'번째 실험')\n","\n","    model.to(device) \n","    contexts.to(device)\n","    target.to(device)\n","\n","    output = model(contexts, target)\n","    optimizer.zero_grad()\n","    output.backward(retain_graph=True)\n","    optimizer.step()\n","   \n","    i += 1\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Z5KGej6QvsJt","executionInfo":{"status":"error","timestamp":1673496568714,"user_tz":-540,"elapsed":12492,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"9bdb4514-d78e-4d36-b697-1ce995dd6682"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["===================================\n","1 번째 실험\n","===================================\n","2 번째 실험\n","===================================\n","3 번째 실험\n","===================================\n","4 번째 실험\n","===================================\n","5 번째 실험\n","===================================\n","6 번째 실험\n","===================================\n","7 번째 실험\n","===================================\n","8 번째 실험\n","===================================\n","9 번째 실험\n","===================================\n","10 번째 실험\n","===================================\n","11 번째 실험\n","===================================\n","12 번째 실험\n","===================================\n","13 번째 실험\n","===================================\n","14 번째 실험\n","===================================\n","15 번째 실험\n","===================================\n","16 번째 실험\n","===================================\n","17 번째 실험\n","===================================\n","18 번째 실험\n","===================================\n","19 번째 실험\n","===================================\n","20 번째 실험\n","===================================\n","21 번째 실험\n","===================================\n","22 번째 실험\n","===================================\n","23 번째 실험\n","===================================\n","24 번째 실험\n","===================================\n","25 번째 실험\n","===================================\n","26 번째 실험\n","===================================\n","27 번째 실험\n","===================================\n","28 번째 실험\n","===================================\n","29 번째 실험\n","===================================\n","30 번째 실험\n","===================================\n","31 번째 실험\n","===================================\n","32 번째 실험\n","===================================\n","33 번째 실험\n","===================================\n","34 번째 실험\n","===================================\n","35 번째 실험\n","===================================\n","36 번째 실험\n","===================================\n","37 번째 실험\n","===================================\n","38 번째 실험\n","===================================\n","39 번째 실험\n","===================================\n","40 번째 실험\n","===================================\n","41 번째 실험\n","===================================\n","42 번째 실험\n","===================================\n","43 번째 실험\n","===================================\n","44 번째 실험\n","===================================\n","45 번째 실험\n","===================================\n","46 번째 실험\n","===================================\n","47 번째 실험\n","===================================\n","48 번째 실험\n","===================================\n","49 번째 실험\n","===================================\n","50 번째 실험\n","===================================\n","51 번째 실험\n","===================================\n","52 번째 실험\n","===================================\n","53 번째 실험\n","===================================\n","54 번째 실험\n","===================================\n","55 번째 실험\n","===================================\n","56 번째 실험\n","===================================\n","57 번째 실험\n","===================================\n","58 번째 실험\n","===================================\n","59 번째 실험\n","===================================\n","60 번째 실험\n","===================================\n","61 번째 실험\n","===================================\n","62 번째 실험\n","===================================\n","63 번째 실험\n","===================================\n","64 번째 실험\n","===================================\n","65 번째 실험\n","===================================\n","66 번째 실험\n","===================================\n","67 번째 실험\n","===================================\n","68 번째 실험\n","===================================\n","69 번째 실험\n","===================================\n","70 번째 실험\n","===================================\n","71 번째 실험\n","===================================\n","72 번째 실험\n","===================================\n","73 번째 실험\n","===================================\n","74 번째 실험\n","===================================\n","75 번째 실험\n","===================================\n","76 번째 실험\n","===================================\n","77 번째 실험\n","===================================\n","78 번째 실험\n","===================================\n","79 번째 실험\n","===================================\n","80 번째 실험\n","===================================\n","81 번째 실험\n","===================================\n","82 번째 실험\n","===================================\n","83 번째 실험\n","===================================\n","84 번째 실험\n","===================================\n","85 번째 실험\n","===================================\n","86 번째 실험\n","===================================\n","87 번째 실험\n","===================================\n","88 번째 실험\n","===================================\n","89 번째 실험\n","===================================\n","90 번째 실험\n","===================================\n","91 번째 실험\n","===================================\n","92 번째 실험\n","===================================\n","93 번째 실험\n","===================================\n","94 번째 실험\n","===================================\n","95 번째 실험\n","===================================\n","96 번째 실험\n","===================================\n","97 번째 실험\n","===================================\n","98 번째 실험\n","===================================\n","99 번째 실험\n","===================================\n","100 번째 실험\n","===================================\n","101 번째 실험\n","===================================\n","102 번째 실험\n","===================================\n","103 번째 실험\n","===================================\n","104 번째 실험\n","===================================\n","105 번째 실험\n","===================================\n","106 번째 실험\n","===================================\n","107 번째 실험\n","===================================\n","108 번째 실험\n","===================================\n","109 번째 실험\n","===================================\n","110 번째 실험\n","===================================\n","111 번째 실험\n","===================================\n","112 번째 실험\n","===================================\n","113 번째 실험\n","===================================\n","114 번째 실험\n","===================================\n","115 번째 실험\n","===================================\n","116 번째 실험\n","===================================\n","117 번째 실험\n","===================================\n","118 번째 실험\n","===================================\n","119 번째 실험\n","===================================\n","120 번째 실험\n","===================================\n","121 번째 실험\n","===================================\n","122 번째 실험\n","===================================\n","123 번째 실험\n","===================================\n","124 번째 실험\n","===================================\n","125 번째 실험\n","===================================\n","126 번째 실험\n","===================================\n","127 번째 실험\n","===================================\n","128 번째 실험\n","===================================\n","129 번째 실험\n","===================================\n","130 번째 실험\n","===================================\n","131 번째 실험\n","===================================\n","132 번째 실험\n","===================================\n","133 번째 실험\n","===================================\n","134 번째 실험\n","===================================\n","135 번째 실험\n","===================================\n","136 번째 실험\n","===================================\n","137 번째 실험\n","===================================\n","138 번째 실험\n","===================================\n","139 번째 실험\n","===================================\n","140 번째 실험\n","===================================\n","141 번째 실험\n","===================================\n","142 번째 실험\n","===================================\n","143 번째 실험\n","===================================\n","144 번째 실험\n","===================================\n","145 번째 실험\n","===================================\n","146 번째 실험\n","===================================\n","147 번째 실험\n","===================================\n","148 번째 실험\n","===================================\n","149 번째 실험\n","===================================\n","150 번째 실험\n","===================================\n","151 번째 실험\n","===================================\n","152 번째 실험\n","===================================\n","153 번째 실험\n","===================================\n","154 번째 실험\n","===================================\n","155 번째 실험\n","===================================\n","156 번째 실험\n","===================================\n","157 번째 실험\n","===================================\n","158 번째 실험\n","===================================\n","159 번째 실험\n","===================================\n","160 번째 실험\n","===================================\n","161 번째 실험\n","===================================\n","162 번째 실험\n","===================================\n","163 번째 실험\n","===================================\n","164 번째 실험\n","===================================\n","165 번째 실험\n","===================================\n","166 번째 실험\n","===================================\n","167 번째 실험\n","===================================\n","168 번째 실험\n","===================================\n","169 번째 실험\n","===================================\n","170 번째 실험\n","===================================\n","171 번째 실험\n","===================================\n","172 번째 실험\n","===================================\n","173 번째 실험\n","===================================\n","174 번째 실험\n","===================================\n","175 번째 실험\n","===================================\n","176 번째 실험\n","===================================\n","177 번째 실험\n","===================================\n","178 번째 실험\n","===================================\n","179 번째 실험\n","===================================\n","180 번째 실험\n","===================================\n","181 번째 실험\n","===================================\n","182 번째 실험\n","===================================\n","183 번째 실험\n","===================================\n","184 번째 실험\n","===================================\n","185 번째 실험\n","===================================\n","186 번째 실험\n","===================================\n","187 번째 실험\n","===================================\n","188 번째 실험\n","===================================\n","189 번째 실험\n","===================================\n","190 번째 실험\n","===================================\n","191 번째 실험\n","===================================\n","192 번째 실험\n","===================================\n","193 번째 실험\n","===================================\n","194 번째 실험\n","===================================\n","195 번째 실험\n","===================================\n","196 번째 실험\n","===================================\n","197 번째 실험\n","===================================\n","198 번째 실험\n","===================================\n","199 번째 실험\n","===================================\n","200 번째 실험\n","===================================\n","201 번째 실험\n","===================================\n","202 번째 실험\n","===================================\n","203 번째 실험\n","===================================\n","204 번째 실험\n","===================================\n","205 번째 실험\n","===================================\n","206 번째 실험\n","===================================\n","207 번째 실험\n","===================================\n","208 번째 실험\n","===================================\n","209 번째 실험\n","===================================\n","210 번째 실험\n","===================================\n","211 번째 실험\n","===================================\n","212 번째 실험\n","===================================\n","213 번째 실험\n","===================================\n","214 번째 실험\n","===================================\n","215 번째 실험\n","===================================\n","216 번째 실험\n","===================================\n","217 번째 실험\n","===================================\n","218 번째 실험\n","===================================\n","219 번째 실험\n","===================================\n","220 번째 실험\n","===================================\n","221 번째 실험\n","===================================\n","222 번째 실험\n","===================================\n","223 번째 실험\n","===================================\n","224 번째 실험\n","===================================\n","225 번째 실험\n","===================================\n","226 번째 실험\n","===================================\n","227 번째 실험\n","===================================\n","228 번째 실험\n","===================================\n","229 번째 실험\n","===================================\n","230 번째 실험\n","===================================\n","231 번째 실험\n","===================================\n","232 번째 실험\n","===================================\n","233 번째 실험\n","===================================\n","234 번째 실험\n","===================================\n","235 번째 실험\n","===================================\n","236 번째 실험\n","===================================\n","237 번째 실험\n","===================================\n","238 번째 실험\n","===================================\n","239 번째 실험\n","===================================\n","240 번째 실험\n","===================================\n","241 번째 실험\n","===================================\n","242 번째 실험\n","===================================\n","243 번째 실험\n","===================================\n","244 번째 실험\n","===================================\n","245 번째 실험\n","===================================\n","246 번째 실험\n","===================================\n","247 번째 실험\n","===================================\n","248 번째 실험\n","===================================\n","249 번째 실험\n","===================================\n","250 번째 실험\n","===================================\n","251 번째 실험\n","===================================\n","252 번째 실험\n","===================================\n","253 번째 실험\n","===================================\n","254 번째 실험\n","===================================\n","255 번째 실험\n","===================================\n","256 번째 실험\n","===================================\n","257 번째 실험\n","===================================\n","258 번째 실험\n","===================================\n","259 번째 실험\n","===================================\n","260 번째 실험\n","===================================\n","261 번째 실험\n","===================================\n","262 번째 실험\n","===================================\n","263 번째 실험\n","===================================\n","264 번째 실험\n","===================================\n","265 번째 실험\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-cf8e99bb2bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# 6. 모델 설정 완료\n","---"],"metadata":{"id":"OEtKJleExL0w"}},{"cell_type":"markdown","source":["### word2vec 모델 최종 완성\n","pre_h와 NegativeSampling을 합치자"],"metadata":{"id":"892gaytGLB86"}},{"cell_type":"code","source":["class CBOW(nn.Module):\n","    def __init__(self, vocab_size, hidden_size, corpus, window_size, power = 0.75, sample_size = 5):\n","        super().__init__()\n","        self.window_size = window_size\n","        self.in_layer = nn.Embedding(vocab_size, hidden_size)\n","        self.out_layer = NegativeSampling(vocab_size, hidden_size, corpus, device, power, sample_size)\n","\n","    def forward(self, contexts, target):\n","        h = 0\n","        for i in range(2 * self.window_size):\n","            weight = self.in_layer(contexts[:,i])\n","            h = h + weight\n","        h = h / int(2 * self.window_size)\n","\n","        out = self.out_layer(h, target)\n","\n","        return out\n","\n","    def get_word_vecs(self):\n","        self.w_in = self.in_layer.weight.data\n","        return self.w_in"],"metadata":{"id":"XNR2PET_LPlG","executionInfo":{"status":"ok","timestamp":1673528104075,"user_tz":-540,"elapsed":2,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### 모델 학습"],"metadata":{"id":"DqNW3vNIPE_-"}},{"cell_type":"code","source":["def train_model(model, dataloaders, optimizer, device, num_epochs=5):\n","    since = time.time()\n","    loss_history = [] # 각 에폭마다 손실함수값 저장\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","\n","        running_loss = 0.0 # 손실 함수\n","        running_corrects = 0 # 정답갯수\n","\n","        for contexts, targets in dataloaders:\n","            contexts = contexts.to(device)\n","            targets = targets.to(device)\n","\n","            outputs = model(contexts, targets) \n","            optimizer.zero_grad()\n","            outputs.backward() \n","            optimizer.step() \n","\n","            running_loss += outputs.item() \n","\n","        epoch_loss = running_loss / len(dataloaders.dataset)\n","\n","        print('Loss: {:.4f} '.format(epoch_loss)) \n","        loss_history.append(epoch_loss)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since # 실행 시간 계산\n","    print(f'실행 시간 : {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","\n","    return loss_history\n"],"metadata":{"id":"bGThodJrwVRi","executionInfo":{"status":"ok","timestamp":1673528105173,"user_tz":-540,"elapsed":1,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# 하이퍼 파라미터 설정\n","vocab_size = len(id_to_word)\n","hidden_size = 100\n","window_size = 5\n","learning_rate = 0.001\n","\n","# device 위치 설정\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"지금 사용하는 device :\",device)\n","\n","# 데이터셋 준비\n","corpus, word_to_id, id_to_word = ptb.load_data('train')\n","\n","contexts, target = create_contexts_target(corpus, window_size)\n","\n","dataset = Corpus_Dataset(corpus, window_size)\n","\n","dataloader = DataLoader(dataset, batch_size = 100)\n","\n","# 모델 설정\n","model = CBOW(vocab_size, hidden_size, corpus, window_size)\n","model.to(device)\n","\n","# 옵티마이저 설정\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # 아담으로 옵티마이저 설정\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQMo9GxP2CgJ","executionInfo":{"status":"ok","timestamp":1673528120490,"user_tz":-540,"elapsed":13476,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"0e70264b-3482-42fb-89f6-cca3cd28fa47"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["지금 사용하는 device : cuda:0\n"]}]},{"cell_type":"code","source":["# 모델 학습\n","loss_history = train_model(model, dataloader, optimizer, device, num_epochs = 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQRi6HMS4f_y","executionInfo":{"status":"ok","timestamp":1673534063428,"user_tz":-540,"elapsed":5941475,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"20e53c68-5ea1-4cbb-bab8-6f270d3a8810"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/99\n","----------\n","Loss: 4.6344 \n","\n","Epoch 1/99\n","----------\n","Loss: 4.6087 \n","\n","Epoch 2/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 3/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 4/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 5/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 6/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 7/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 8/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 9/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 10/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 11/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 12/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 13/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 14/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 15/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 16/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 17/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 18/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 19/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 20/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 21/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 22/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 23/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 24/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 25/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 26/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 27/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 28/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 29/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 30/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 31/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 32/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 33/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 34/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 35/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 36/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 37/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 38/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 39/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 40/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 41/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 42/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 43/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 44/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 45/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 46/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 47/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 48/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 49/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 50/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 51/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 52/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 53/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 54/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 55/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 56/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 57/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 58/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 59/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 60/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 61/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 62/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 63/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 64/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 65/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 66/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 67/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 68/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 69/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 70/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 71/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 72/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 73/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 74/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 75/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 76/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 77/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 78/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 79/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 80/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 81/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 82/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 83/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 84/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 85/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 86/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 87/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 88/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 89/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 90/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 91/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 92/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 93/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 94/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 95/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 96/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 97/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 98/99\n","----------\n","Loss: 4.6052 \n","\n","Epoch 99/99\n","----------\n","Loss: 4.6052 \n","\n","실행 시간 : 99m 1s\n"]}]},{"cell_type":"markdown","source":["이제 나온 가중치를 저장해주자"],"metadata":{"id":"IOkdoxAObKPW"}},{"cell_type":"code","source":["w_in = model.get_word_vecs()\n","print(w_in)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_pDx2QEZ9Hn","executionInfo":{"status":"ok","timestamp":1673534148012,"user_tz":-540,"elapsed":3,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"fbad5693-27ff-4552-a7a1-811c67133535"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.9449, -0.5849,  0.0161,  ..., -1.0903, -0.9557, -0.5309],\n","        [-0.1289, -0.0103,  1.3929,  ..., -1.5256,  0.0590,  0.1824],\n","        [-1.3700,  0.3019, -0.8534,  ...,  0.6650, -1.5444, -1.7060],\n","        ...,\n","        [ 1.4783,  1.9061, -0.9655,  ..., -1.3951,  0.0530, -0.5620],\n","        [-0.3938,  2.5629,  1.2125,  ...,  1.4927,  1.9931, -0.1719],\n","        [ 1.7126, -0.2137, -0.9912,  ...,  0.5755,  2.7250,  0.1613]],\n","       device='cuda:0')\n"]}]},{"cell_type":"code","source":["torch.save(w_in,'./word_vecs.t')"],"metadata":{"id":"vNRrlWqYaJnS","executionInfo":{"status":"ok","timestamp":1673534207997,"user_tz":-540,"elapsed":351,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["npy로도 저장해두겠다."],"metadata":{"id":"-7QJOOR0bOlX"}},{"cell_type":"code","source":["w_in = w_in.cpu().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"rJf0PINOarKY","executionInfo":{"status":"error","timestamp":1673534367937,"user_tz":-540,"elapsed":933,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"17fbaa75-bfb4-4e18-ad5a-2c9a1935635f"},"execution_count":28,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-43e6581dd4cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"]}]},{"cell_type":"code","source":["print(w_in)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PcAj-whWbBla","executionInfo":{"status":"ok","timestamp":1673534387501,"user_tz":-540,"elapsed":3,"user":{"displayName":"오태균","userId":"08325941356492807162"}},"outputId":"09580719-a024-4e53-fcb9-6f9a4876f8b3"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.94492143 -0.5848655   0.01614317 ... -1.0903388  -0.9557403\n","  -0.5308652 ]\n"," [-0.1288693  -0.01029203  1.3928933  ... -1.5256437   0.05897268\n","   0.1823535 ]\n"," [-1.3700342   0.30185702 -0.8534287  ...  0.66502535 -1.5444052\n","  -1.7059944 ]\n"," ...\n"," [ 1.4783314   1.9061414  -0.965526   ... -1.3950768   0.05301956\n","  -0.5619554 ]\n"," [-0.39383167  2.5629487   1.2125373  ...  1.4927211   1.9930971\n","  -0.17194422]\n"," [ 1.7126251  -0.21373655 -0.99115103 ...  0.5755051   2.7250323\n","   0.16133635]]\n"]}]},{"cell_type":"code","source":["np.save('./npy_word_vecs',w_in)"],"metadata":{"id":"6K9qmawvaysB","executionInfo":{"status":"ok","timestamp":1673534401750,"user_tz":-540,"elapsed":1032,"user":{"displayName":"오태균","userId":"08325941356492807162"}}},"execution_count":30,"outputs":[]}]}