{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3 - word2vec\n",
    "\n",
    "\n",
    "#### 3.1 추론 기반 기법과 신경망\n",
    "---\n",
    "1. 통계 기반 기법의 문제점\n",
    "\n",
    "\t- 통계 기반 : 배치 학습 단 1회의 에폭만에 단어의 분산 표현을 얻는다 단, 어휘가 100만대라면 메모리나 계산 속도 관점에서 문제가 생길 수 있다\n",
    "\n",
    "\t- 추론 기반 : 데이터 전부를 한번에 사용할 수 없다면 당연히 우리가 할 수 있는 일은 일부를 추출해서 전체를 예측하는 수 밖에 없다. (확률과 통계의 상황을 생각해라) 미니 배치 학습을 시켜서 가중치를 갱신한다\n",
    "\n",
    "\t![g](../image/image_6.png)\n",
    "\n",
    "\n",
    "2. 추론 기반 기법 개요\n",
    "\n",
    "\t![d](../image/image_7.png)\n",
    "\t\n",
    "\t- 말뭉치의 어휘 수가 많아 SVD등 계산량이 큰 작업을 처리하기 어려운 경우에도 신경망을 학습시킬 수 있다는 뜻입니다. \n",
    "\n",
    "\t\t데이터를 작게 나눠 학습하기 때문이죠. 게다가 여러 머신과 여러 GPU를 이용한 병렬 계산도 가능해져서 학습 속도를 높일 수도 있습니다. \n",
    "\n",
    "\t\t추론 기반 기법이 큰 힘을 발휘하는 영역이죠\n",
    "\n",
    "\t- 말 그대로 모델이 추론 문제를 풀고 학습하는 기법\n",
    "\t</br></br>\n",
    "\n",
    "3. 신경망에서의 단어 처리\n",
    "\n",
    "\t![j](../image/image_8.png)\n",
    "\n",
    "\t- 단어 자체를 처리할 수 없으니 단어들을 원핫 벡터로 바꾸어야 한다\n",
    "\n",
    "\n",
    "#### 3.2 단순한 word2vec\n",
    "---\n",
    "- word2vec 문맥을 벡터로 바꾸는데 쓰이는 기법들 중 CBOW모델이 가장 추천 된다. (skip-gram 모\t델도 있다)\n",
    "\n",
    "1. CBOW 모델의 추론 처리\n",
    "\t- 까먹지 마라. 우리의 목표는 추론 기반 기법을 이용해서 가능한 한 정확하게 추론하도록 훈련시켜서 단어의 분산 표현을 얻는 것이다\n",
    "\n",
    "\t![a](../image/image_9.png)\n",
    "\t![b](../image/image_10.png)\n",
    "\n",
    "\t</br></br>\n",
    "\n",
    "2. CBOW 모델의 학습\n",
    "\n",
    "\t![c](../image/image_11.png)\n",
    "\t![d](../image/image_12.png)\n",
    "\n",
    "3. word2vec의 가중치와 분산 표현\n",
    "\t- 입력측의 가중치를 단어의 분산 표현으로 사용할 것이다\n",
    "\n",
    "\t![a](../image/image_13.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 학습 데이터 준비\n",
    "---\n",
    "1. 맥락과 타깃\n",
    "\t- 말뭉치로부터 추론 모델에 쓰일 데이터셋을 추출하자!\n",
    "\n",
    "\t![](../image/image_14.png)\n",
    "\n",
    "\t![](../image/image_15.png)\n",
    "\n",
    "2. 원핫 표현으로 변환\n",
    "\t- 근데 맥락과 타깃의 각 원소는 단어 ID가 아닌 원핫벡터여야 한다! (고유 스칼라 값이 아닌 벡터여야 한다!)\n",
    "\n",
    "\t![](../image/image_16.png)\n",
    "\n",
    "#### 3.4 CBOW 모델 구현\n",
    "---\n",
    "1. 학습 코드 구현\n",
    "\n",
    "\n",
    "#### 3.5 word2vec 보충\n",
    "---\n",
    "1. CBOW 모델과 확률\n",
    "\n",
    "2. skip-gram 모델\n",
    "\n",
    "3. 통계기반 vs 추론 기반\n",
    "\t- 의외로 정확도 부분에서는 통계 기반이나 추론 기반이나 우열을 가릴 수 없지만...\n",
    "\n",
    "\t새로운 단어가 추가한다면 통계 기반은 처음부터 죄다 계산을 해야하지만\n",
    "\n",
    "\t추론 기반은 이전에 학습한 가중치를 초깃값으로 사용해 다시 계산하면 그만이다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_studing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (default, Nov 15 2020, 08:30:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d060f0828fc2b117241290c294bd7cf3e183c40a44f56e1a2627712ee0c7af9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
